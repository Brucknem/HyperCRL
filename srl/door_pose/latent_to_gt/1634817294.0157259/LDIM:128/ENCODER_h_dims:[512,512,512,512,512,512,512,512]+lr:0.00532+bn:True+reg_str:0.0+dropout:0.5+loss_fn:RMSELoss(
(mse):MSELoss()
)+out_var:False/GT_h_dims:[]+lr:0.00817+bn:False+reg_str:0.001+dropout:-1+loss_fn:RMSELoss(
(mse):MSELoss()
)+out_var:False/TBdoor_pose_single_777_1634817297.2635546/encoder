digraph {
	graph [size="33.449999999999996,33.449999999999996"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140578177819488 [label="
 (10, 128)" fillcolor=darkolivegreen1]
	140578182651072 [label=LeakyReluBackward0]
	140578182650960 -> 140578182651072
	140578182650960 [label=AddmmBackward]
	140578182650848 -> 140578182650960
	140578182526512 [label="linear.8.bias
 (128)" fillcolor=lightblue]
	140578182526512 -> 140578182650848
	140578182650848 [label=AccumulateGrad]
	140578182650904 -> 140578182650960
	140578182650904 [label=FusedDropoutBackward]
	140578182650624 -> 140578182650904
	140578182650624 [label=NativeBatchNormBackward]
	140578182650512 -> 140578182650624
	140578182650512 [label=LeakyReluBackward0]
	140578182650288 -> 140578182650512
	140578182650288 [label=AddmmBackward]
	140578182650176 -> 140578182650288
	140578182526368 [label="linear.7.bias
 (512)" fillcolor=lightblue]
	140578182526368 -> 140578182650176
	140578182650176 [label=AccumulateGrad]
	140578182650120 -> 140578182650288
	140578182650120 [label=FusedDropoutBackward]
	140578182649952 -> 140578182650120
	140578182649952 [label=NativeBatchNormBackward]
	140578182649840 -> 140578182649952
	140578182649840 [label=LeakyReluBackward0]
	140578182649616 -> 140578182649840
	140578182649616 [label=AddmmBackward]
	140578182649504 -> 140578182649616
	140578182526224 [label="linear.6.bias
 (512)" fillcolor=lightblue]
	140578182526224 -> 140578182649504
	140578182649504 [label=AccumulateGrad]
	140578182649448 -> 140578182649616
	140578182649448 [label=FusedDropoutBackward]
	140578182649280 -> 140578182649448
	140578182649280 [label=NativeBatchNormBackward]
	140578182649168 -> 140578182649280
	140578182649168 [label=LeakyReluBackward0]
	140578182648944 -> 140578182649168
	140578182648944 [label=AddmmBackward]
	140578182648832 -> 140578182648944
	140578182526080 [label="linear.5.bias
 (512)" fillcolor=lightblue]
	140578182526080 -> 140578182648832
	140578182648832 [label=AccumulateGrad]
	140578182648776 -> 140578182648944
	140578182648776 [label=FusedDropoutBackward]
	140578182648608 -> 140578182648776
	140578182648608 [label=NativeBatchNormBackward]
	140578182648496 -> 140578182648608
	140578182648496 [label=LeakyReluBackward0]
	140578182648272 -> 140578182648496
	140578182648272 [label=AddmmBackward]
	140578182651184 -> 140578182648272
	140578182525936 [label="linear.4.bias
 (512)" fillcolor=lightblue]
	140578182525936 -> 140578182651184
	140578182651184 [label=AccumulateGrad]
	140578182651240 -> 140578182648272
	140578182651240 [label=FusedDropoutBackward]
	140578182651408 -> 140578182651240
	140578182651408 [label=NativeBatchNormBackward]
	140578182651520 -> 140578182651408
	140578182651520 [label=LeakyReluBackward0]
	140578182651744 -> 140578182651520
	140578182651744 [label=AddmmBackward]
	140578182651856 -> 140578182651744
	140578182525792 [label="linear.3.bias
 (512)" fillcolor=lightblue]
	140578182525792 -> 140578182651856
	140578182651856 [label=AccumulateGrad]
	140578177871944 -> 140578182651744
	140578177871944 [label=FusedDropoutBackward]
	140578177872112 -> 140578177871944
	140578177872112 [label=NativeBatchNormBackward]
	140578177872224 -> 140578177872112
	140578177872224 [label=LeakyReluBackward0]
	140578177872448 -> 140578177872224
	140578177872448 [label=AddmmBackward]
	140578177872560 -> 140578177872448
	140578182525648 [label="linear.2.bias
 (512)" fillcolor=lightblue]
	140578182525648 -> 140578177872560
	140578177872560 [label=AccumulateGrad]
	140578177872616 -> 140578177872448
	140578177872616 [label=FusedDropoutBackward]
	140578177872840 -> 140578177872616
	140578177872840 [label=NativeBatchNormBackward]
	140578177872952 -> 140578177872840
	140578177872952 [label=LeakyReluBackward0]
	140578177873176 -> 140578177872952
	140578177873176 [label=AddmmBackward]
	140578177873344 -> 140578177873176
	140578182525504 [label="linear.1.bias
 (512)" fillcolor=lightblue]
	140578182525504 -> 140578177873344
	140578177873344 [label=AccumulateGrad]
	140578177873400 -> 140578177873176
	140578177873400 [label=FusedDropoutBackward]
	140578177873624 -> 140578177873400
	140578177873624 [label=NativeBatchNormBackward]
	140578177873736 -> 140578177873624
	140578177873736 [label=LeakyReluBackward0]
	140578177873960 -> 140578177873736
	140578177873960 [label=AddmmBackward]
	140578177874128 -> 140578177873960
	140578182525360 [label="linear.0.bias
 (512)" fillcolor=lightblue]
	140578182525360 -> 140578177874128
	140578177874128 [label=AccumulateGrad]
	140578177874184 -> 140578177873960
	140578177874184 [label=TBackward]
	140578177874352 -> 140578177874184
	140578182525288 [label="linear.0.weight
 (512, 512)" fillcolor=lightblue]
	140578182525288 -> 140578177874352
	140578177874352 [label=AccumulateGrad]
	140578177873792 -> 140578177873624
	140578182465288 [label="bn.0.weight
 (512)" fillcolor=lightblue]
	140578182465288 -> 140578177873792
	140578177873792 [label=AccumulateGrad]
	140578177873848 -> 140578177873624
	140578182465360 [label="bn.0.bias
 (512)" fillcolor=lightblue]
	140578182465360 -> 140578177873848
	140578177873848 [label=AccumulateGrad]
	140578177873456 -> 140578177873176
	140578177873456 [label=TBackward]
	140578177873680 -> 140578177873456
	140578182525432 [label="linear.1.weight
 (512, 512)" fillcolor=lightblue]
	140578182525432 -> 140578177873680
	140578177873680 [label=AccumulateGrad]
	140578177873008 -> 140578177872840
	140578182465648 [label="bn.1.weight
 (512)" fillcolor=lightblue]
	140578182465648 -> 140578177873008
	140578177873008 [label=AccumulateGrad]
	140578177873064 -> 140578177872840
	140578182465720 [label="bn.1.bias
 (512)" fillcolor=lightblue]
	140578182465720 -> 140578177873064
	140578177873064 [label=AccumulateGrad]
	140578177872672 -> 140578177872448
	140578177872672 [label=TBackward]
	140578177872896 -> 140578177872672
	140578182525576 [label="linear.2.weight
 (512, 512)" fillcolor=lightblue]
	140578182525576 -> 140578177872896
	140578177872896 [label=AccumulateGrad]
	140578177872280 -> 140578177872112
	140573391177120 [label="bn.2.weight
 (512)" fillcolor=lightblue]
	140573391177120 -> 140578177872280
	140578177872280 [label=AccumulateGrad]
	140578177872336 -> 140578177872112
	140578319951408 [label="bn.2.bias
 (512)" fillcolor=lightblue]
	140578319951408 -> 140578177872336
	140578177872336 [label=AccumulateGrad]
	140578177872000 -> 140578182651744
	140578177872000 [label=TBackward]
	140578177872168 -> 140578177872000
	140578182525720 [label="linear.3.weight
 (512, 512)" fillcolor=lightblue]
	140578182525720 -> 140578177872168
	140578177872168 [label=AccumulateGrad]
	140578182651576 -> 140578182651408
	140578182466080 [label="bn.3.weight
 (512)" fillcolor=lightblue]
	140578182466080 -> 140578182651576
	140578182651576 [label=AccumulateGrad]
	140578182651632 -> 140578182651408
	140578182466152 [label="bn.3.bias
 (512)" fillcolor=lightblue]
	140578182466152 -> 140578182651632
	140578182651632 [label=AccumulateGrad]
	140578182651296 -> 140578182648272
	140578182651296 [label=TBackward]
	140578182651464 -> 140578182651296
	140578182525864 [label="linear.4.weight
 (512, 512)" fillcolor=lightblue]
	140578182525864 -> 140578182651464
	140578182651464 [label=AccumulateGrad]
	140578182648440 -> 140578182648608
	140578182466440 [label="bn.4.weight
 (512)" fillcolor=lightblue]
	140578182466440 -> 140578182648440
	140578182648440 [label=AccumulateGrad]
	140578182648384 -> 140578182648608
	140578182466512 [label="bn.4.bias
 (512)" fillcolor=lightblue]
	140578182466512 -> 140578182648384
	140578182648384 [label=AccumulateGrad]
	140578182648720 -> 140578182648944
	140578182648720 [label=TBackward]
	140578182648552 -> 140578182648720
	140578182526008 [label="linear.5.weight
 (512, 512)" fillcolor=lightblue]
	140578182526008 -> 140578182648552
	140578182648552 [label=AccumulateGrad]
	140578182649112 -> 140578182649280
	140578182466800 [label="bn.5.weight
 (512)" fillcolor=lightblue]
	140578182466800 -> 140578182649112
	140578182649112 [label=AccumulateGrad]
	140578182649056 -> 140578182649280
	140578182466872 [label="bn.5.bias
 (512)" fillcolor=lightblue]
	140578182466872 -> 140578182649056
	140578182649056 [label=AccumulateGrad]
	140578182649392 -> 140578182649616
	140578182649392 [label=TBackward]
	140578182649224 -> 140578182649392
	140578182526152 [label="linear.6.weight
 (512, 512)" fillcolor=lightblue]
	140578182526152 -> 140578182649224
	140578182649224 [label=AccumulateGrad]
	140578182649784 -> 140578182649952
	140578182467160 [label="bn.6.weight
 (512)" fillcolor=lightblue]
	140578182467160 -> 140578182649784
	140578182649784 [label=AccumulateGrad]
	140578182649728 -> 140578182649952
	140578182467232 [label="bn.6.bias
 (512)" fillcolor=lightblue]
	140578182467232 -> 140578182649728
	140578182649728 [label=AccumulateGrad]
	140578182650064 -> 140578182650288
	140578182650064 [label=TBackward]
	140578182649896 -> 140578182650064
	140578182526296 [label="linear.7.weight
 (512, 512)" fillcolor=lightblue]
	140578182526296 -> 140578182649896
	140578182649896 [label=AccumulateGrad]
	140578182650456 -> 140578182650624
	140578182467520 [label="bn.7.weight
 (512)" fillcolor=lightblue]
	140578182467520 -> 140578182650456
	140578182650456 [label=AccumulateGrad]
	140578182650400 -> 140578182650624
	140578182525000 [label="bn.7.bias
 (512)" fillcolor=lightblue]
	140578182525000 -> 140578182650400
	140578182650400 [label=AccumulateGrad]
	140578182650736 -> 140578182650960
	140578182650736 [label=TBackward]
	140578182650568 -> 140578182650736
	140578182526440 [label="linear.8.weight
 (128, 512)" fillcolor=lightblue]
	140578182526440 -> 140578182650568
	140578182650568 [label=AccumulateGrad]
	140578182651072 -> 140578177819488
}
